{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "source": [
    "## Lisence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Modifications copyright 2020 Dennis Adelved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "#if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
    "  #raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n",
    "\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the path to the folder containing the exported inference graph\n",
    "MODEL_NAME = 'M2_inference_graph'\n",
    "\n",
    "#adding the frozen inference graph to the path\n",
    "PATH_TO_FROZEN_GRAPH = os.path.join(MODEL_NAME,'frozen_inference_graph.pb')\n",
    "\n",
    "#Path to the label map\n",
    "PATH_TO_LABELS = 'labelmap.pbtxt'\n",
    "\n",
    "#Path to the images that are used for inference. Here only three sample images are given.\n",
    "#However, more can be added to this directory\n",
    "PATH_TO_TEST_IMAGES_DIR = 'images'\n",
    "\n",
    "#The output directory for the cropped core images. If no cropping is desired set OUTPUT_DIR = None\n",
    "OUTPUT_DIR = os.path.join('auto_generated_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aSlYc3JkWKMa"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run inference on image using the frozen inference graph\n",
    "def run_inference_for_single_image(image, graph):\n",
    "\n",
    "\n",
    "    if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "\n",
    "\n",
    "    image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "    # Run inference\n",
    "    output_dict = sess.run(tensor_dict,\n",
    "                         feed_dict={image_tensor: image})\n",
    "\n",
    "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "    output_dict['detection_classes'] = output_dict[\n",
    "      'detection_classes'][0].astype(np.int64)\n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "    output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "    if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3a5wMHN8WKMh"
   },
   "outputs": [],
   "source": [
    "\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR,'*.jpg'))\n",
    "\n",
    "\n",
    "\n",
    "#empty list for saving the output dicts for each prediction\n",
    "dicts = []\n",
    "IMAGE_SIZE = (20,20)\n",
    "\n",
    "#SET TRUE IF THE PREDICTED BOUNDING BOXES SHALL BE VISUALIZED ON THE INPUT IMAGE\n",
    "VISUALIZE = False\n",
    "\n",
    "\n",
    "#Retrieve the detection data from the inference\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "        ops = tf.get_default_graph().get_operations()\n",
    "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "        tensor_dict = {}\n",
    "        for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "            tensor_name = key + ':0'\n",
    "            if tensor_name in all_tensor_names:\n",
    "                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "\n",
    "        for image_path in TEST_IMAGE_PATHS:\n",
    "            image = Image.open(image_path)\n",
    "            # the array based representation of the image will be used later in order to prepare the\n",
    "            # result image with boxes and labels on it.\n",
    "\n",
    "            #image_np = load_image_into_numpy_array(image) #funker ikke for alle typer input graph\n",
    "\n",
    "            a = np.asarray(image)\n",
    "            image_np = np.copy(a[:,:,0:3])\n",
    "\n",
    "\n",
    "\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "            # Actual detection.\n",
    "            output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)  \n",
    "            \n",
    "            #append detection from image to the detection list\n",
    "            dicts.append(output_dict)\n",
    "            \n",
    "            # Visualization of the results of a detection. \n",
    "            #(comment out this block if the visualization slows down the running time of the script)\n",
    "            if VISUALIZE==True:\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                  image_np,\n",
    "                  output_dict['detection_boxes'],\n",
    "                  output_dict['detection_classes'],\n",
    "                  output_dict['detection_scores'],\n",
    "                  category_index,\n",
    "                  instance_masks=output_dict.get('detection_masks'),\n",
    "                  use_normalized_coordinates=True,\n",
    "                  line_thickness=12)\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.imshow(image_np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denormalize the bounding box coordinates generated by the model\n",
    "def denormalize(array,image):\n",
    "    denorm = array.copy()\n",
    "    h,w = im.shape[0:2]\n",
    "    for i in range(array.shape[0]):\n",
    "        ymin = int(array[i][0][0]*h);\n",
    "        xmin = int(array[i][0][1]*w)\n",
    "        ymax = int(array[i][0][2]*h)\n",
    "        xmax = int(array[i][0][3]*w)\n",
    "        #print(xmin,':',ymin,':',xmax,':',ymax)\n",
    "        denorm[i] = xmin,ymin,xmax,ymax\n",
    "    return denorm\n",
    "\n",
    "#non-max supression function (remove overlaping bounding boxes)\n",
    "def non_max_supression(boxes,overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    pick = []\n",
    "    xmin = boxes[:,0]\n",
    "    ymin = boxes[:,1]\n",
    "    xmax = boxes[:,2]\n",
    "    ymax = boxes[:,3]\n",
    "    area = (xmax - xmin + 1) * (ymax - ymin + 1)\n",
    "    idxs = np.argsort(ymax)\n",
    "    \n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        \n",
    "        xxmin = np.maximum(xmin[i], xmin[idxs[:last]])\n",
    "        yymin = np.maximum(ymin[i], ymin[idxs[:last]])\n",
    "        xxmax = np.minimum(xmax[i], xmax[idxs[:last]])\n",
    "        yymax = np.minimum(ymax[i], ymax[idxs[:last]])\n",
    "        \n",
    "        w = np.maximum(0, xxmax - xxmin + 1)\n",
    "        h = np.maximum(0, yymax - yymin + 1)\n",
    " \n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    " \n",
    "    return boxes[pick].astype(\"int\")\n",
    "    \n",
    "#returns the filename and file extension from the path\n",
    "def get_filename(path):\n",
    "    filename = re.findall('^(.+)/([^/]+)$',path)\n",
    "    filename = filename[0][1].split('.')\n",
    "    return filename\n",
    "\n",
    "def merge_same_col(b): \n",
    "    test = b[b[:,2].argsort()]\n",
    "    i = np.argwhere(abs(np.diff(test[:,2])) < 10)\n",
    "    samecoreind = np.argwhere(abs(test[:,2] - test[:,2][i])< 10)[:,-1]\n",
    "    if len(samecoreind) == 0:\n",
    "        return b\n",
    "    else:\n",
    "        \n",
    "        samecore = test[samecoreind,:]\n",
    "        top = samecore[np.argwhere(samecore[:,1] == min(samecore[:,1])),1]\n",
    "        base = samecore[np.argwhere(samecore[:,-1] == max(samecore[:,-1])),-1]\n",
    "        newrow = samecore[0]\n",
    "        newrow[1] = top\n",
    "        newrow[-1] = base\n",
    "        test = np.delete(test,samecoreind,axis=0)\n",
    "        return np.vstack((test,newrow))\n",
    "    \n",
    "            \n",
    "\n",
    "def auto_annotate_xml(im_path,xml_template_path,predicted_bounding_boxes,output_folder = OUTPUT_DIR):\n",
    "    \n",
    "    output_path = os.path.join(os.getcwd(),output_folder)\n",
    "    new_xml_path = im_path.split('/')[-1].split('.')[0] + '.xml'\n",
    "    xml_copy_path = shutil.copy(xml_template_path, os.path.join(output_path, new_xml_path))\n",
    "    print(xml_copy_path)\n",
    "    \n",
    "    tree = ET.parse(xml_copy_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    im = Image.open(im_path)\n",
    "    im = np.asarray(im)\n",
    "    h,w,d = im.shape\n",
    "\n",
    "    root.find('folder').text = output_path.split('/')[-1]\n",
    "    root.find('filename').text = im_path.split('/')[-1]\n",
    "    root.find('path').text = os.path.join(output_path,im_path.split('/')[-1])\n",
    "    root.find('size').find('width').text = str(w)\n",
    "    root.find('size').find('height').text = str(h)\n",
    "    root.find('size').find('depth').text = str(d)\n",
    "    \n",
    "    new_objects = match_objects(root.findall('object'),predicted_bounding_boxes)\n",
    "    \n",
    "    \n",
    "    for obj in root.findall('object'):\n",
    "        root.remove(obj)\n",
    "    #print(len(root.findall('object')))\n",
    "    \n",
    "    \n",
    "        \n",
    "    for new_obj in new_objects:\n",
    "        root.append(new_obj)\n",
    "    #print(len(root.findall('object')))\n",
    "        \n",
    "    #print(len(root.findall('object')))\n",
    "    #print(len(denorm))\n",
    "    for ind,obj in enumerate(root.findall('object')):\n",
    "\n",
    "        obj.find('name').text = 'core'\n",
    "        obj.find('bndbox').find('ymin').text = str((predicted_bounding_boxes[ind,1]))\n",
    "        obj.find('bndbox').find('xmin').text = str((predicted_bounding_boxes[ind,0]))\n",
    "        obj.find('bndbox').find('ymax').text =str( (predicted_bounding_boxes[ind,3]))\n",
    "        obj.find('bndbox').find('xmax').text = str((predicted_bounding_boxes[ind,2]))\n",
    "\n",
    "    \n",
    "    \n",
    "    shutil.copy(im_path,os.path.join(output_path,im_path.split('/')[-1]))\n",
    "    tree.write(xml_copy_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-generate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/M2_inference_graph_autolabel/auto_generated_labels/1070_23_2671-2675m.xml\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/M2_inference_graph_autolabel/auto_generated_labels/3042_41_2711-2716m.xml\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/M2_inference_graph_autolabel/auto_generated_labels/80_02_1983-1986m.xml\n"
     ]
    }
   ],
   "source": [
    "#zipping the image paths and output_dicts for paralell iteration\n",
    "zipped = list(zip(TEST_IMAGE_PATHS,dicts))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(zipped)):\n",
    "    #extract only the bounding boxes of the predictions with a high detection score\n",
    "    ind = np.argwhere(zipped[i][1]['detection_scores']>.8)\n",
    "\n",
    "    arr = zipped[i][1]['detection_boxes'][ind].copy()\n",
    "    \n",
    "    \n",
    "    filename = get_filename(zipped[i][0])\n",
    "    #open the image, normalize the bounding box coordiantes and apply non-max supression\n",
    "    im = Image.open(zipped[i][0])\n",
    "    im = np.array(im)\n",
    "    b = denormalize(arr,im)\n",
    "    mintop = min(np.squeeze(b)[:,1]) \n",
    "    b = b.reshape(b.shape[0],b.shape[2])\n",
    "    \n",
    "    boxes = non_max_supression(b,0.5)\n",
    "\n",
    "    #display the cropped result\n",
    "    boxes = merge_same_col(boxes)\n",
    "    \n",
    "    auto_annotate_xml(zipped[i][0],'template.xml',boxes)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
